

<h1>Python_Labs</h1>

# –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç
–∞ 1



## –ó–∞–¥–∞–Ω–∏—è

### –ó–∞–¥–∞–Ω–∏–µ 1:

–ü—Ä–æ–≥—Ä–∞–º–º–∞ –≤—ã–≤–æ–¥–∏—Ç –ø—Ä–æ—Å—Ç–æ–µ –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ –≤ –∫–æ–Ω—Å–æ–ª—å.

**–ö–æ–¥:**
```python
name = input("–ò–º—è: ")
age = int(input("–í–æ–∑—Ä–∞—Å—Ç: "))
print(f"–ü—Ä–∏–≤–µ—Ç, {name}! –ß–µ—Ä–µ–∑ –≥–æ–¥ —Ç–µ–±–µ –±—É–¥–µ—Ç {age}.")
```
–†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è:

![–†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞–Ω–∏—è 1](images/lab01/01_greeting.png)

### –ó–∞–¥–∞–Ω–∏–µ 2: 

–ö–æ–¥:

```python
a = (input("a: ")).replace(",",".")
b = (input("b: ")).replace(",",".")
print(f"sum={round(float(a)+float(b), 2)}; avg={round((float(a)+float(b))/2, 2)}")
```
–†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è:

![–†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞–Ω–∏—è 2](images/lab01/02_sum_avg.png)


### –ó–∞–¥–∞–Ω–∏–µ 3: 

```python
price = int(input())
discount = int(input())
vat = int(input())
base = price * (1 - discount/100)
vat_amount = base * (vat/100)
total = base + vat_amount
print(f"–ë–∞–∑–∞ –ø–æ—Å–ª–µ —Å–∫–∏–¥–∫–∏: {base:.2f} ‚ÇΩ")
print(f"–ù–î–°:               {vat_amount:.2f} ‚ÇΩ")
print(f"–ò—Ç–æ–≥–æ –∫ –æ–ø–ª–∞—Ç–µ:    {total:.2f} ‚ÇΩ")
```
–†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è:

![–†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞–Ω–∏—è 3](images/lab01/03_discount_vat.png)

### –ó–∞–¥–∞–Ω–∏–µ 4: 

```python
mm = int(input("–ú–∏–Ω—É—Ç—ã: "))
hh = mm//60
print(f"{hh}:{(mm-60*hh):02d}")
```
–†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è:

![–†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞–Ω–∏—è 4](images/lab01/04_minutes_to_hhmm.png)

### –ó–∞–¥–∞–Ω–∏–µ 5:

```python
fio = input("–§–ò–û: ").split()
I = ''
for i in range(3):
    I += fio[i][0]
print(f"–ò–Ω–∏—Ü–∏–∞–ª—ã: {I}.")
print(sum(len(i) for i in fio)+2)
```

–†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è:

![–†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞–Ω–∏—è 5](images/lab01/05_initials_and_len.png)


### –ó–∞–¥–∞–Ω–∏–µ 6:
```python
n = int(input())
ochno = 0
for i in range(n):
    surname, name, age, form = map(str, input().split(' '))
    if form == 'True':
        ochno+=1
print(ochno, n-ochno)
```

–†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è:

![–†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞–Ω–∏—è 6](images/lab01/ex_06.png)

### –ó–∞–¥–∞–Ω–∏–µ 7:
```python
cipher = input()
ans = ''
n = 0
for i in range(len(cipher)):
    if cipher[i].isupper():
        ans+=cipher[i]
        n = i+1
        break

for i in range(len(cipher)):
    for j in range(2,1000,3):
        if i == n+j:
            ans+=cipher[i]
print(ans)
```

–†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è:

![–†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞–Ω–∏—è 1](images/lab01/ex_07.png)


# –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 2
### –ó–∞–¥–∞–Ω–∏–µ 1:

```python
def min_max(nums):
    if nums==[]:
        return 'ValueError'
    else:
        return (min(nums),max(nums))

def unique_sorted(nums):
    return sorted(set(nums))
def flatten(mat):
    new_mat = []
    for i in mat:
        for j in i:
            if type(j) == str:
                return 'TypeError'
            new_mat.append(j)
    return (new_mat)
```

–†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è:

![–†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞–Ω–∏—è 1](images/lab02/arrays.png)

### –ó–∞–¥–∞–Ω–∏–µ 2:

```python

def transpose(mat):
    if len(mat) == 0:
        return []
    elif len(mat) == 1:
        b = [[] for _ in range(len(mat[0]))]
        for i in range(len(mat[0])):
            b[i] += [(mat[0][i])]
        return b
    elif all(len(mat[i]) == 1 for i in range(len(mat))):
        c = [[]]
        for k in mat:
            c[0] += k
        return c
    elif all(len(mat[i]) == len(mat[i + 1]) for i in range(len(mat[0]) - 1)):
        a = [[] for _ in range(len(mat))]
        for k in range(len(mat)):
            for i in range(len(mat[0])):
                a[k] += [mat[i][k]]
        return a
    else:
        return 'ValueError'

def row_sums(mat):
    k = len(mat[0])
    ans = []
    for i in mat:
        if k == len(i):
            ans.append(sum(i))
        else:
            return 'ValueError'
    return ans

def col_sums(mat):
    ans = [0]*len(mat[0])
    k = len(mat[0])
    for i in range(len(mat)):
        if k==len(mat[i]):
            for j in range(len(mat[i])):
                ans[j]+=mat[i][j]
        else:
            return 'ValueError'
    return ans
```

–†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è:

![–†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞–Ω–∏—è 2](images/lab02/matrix.png)

### –ó–∞–¥–∞–Ω–∏–µ 3:

```python
fio_new = ''
flag1 = False
len_fio = 0
gpa = float
s = input().replace('(','').replace(')','').split(', ')
for i in s:
    if i == '':
        s.append('musor')
if len(s) == 3:
    fio_old = s[0].replace('''"''','').split(' ')
    for i in fio_old:
        if i != '' and flag1 == False:
            fio_new += str(i.capitalize())+' '
            len_fio+=1
            flag1 = True
        elif flag1 == True and i!='':
            fio_new += str(i.capitalize()[0]) + '.'
            len_fio+=1
    group = s[1].replace('''"''','')
    gpa = float(s[2])
    if 3>=len_fio>=2:
        print(f'''"{fio_new}, –≥—Ä. {group}, GPA {gpa:.2f}"''')
    else:
        print('ValueError')
else: print('ValueError')
```

–†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è:

![–†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞–Ω–∏—è 3](images/lab02/tuples.png)


# –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 3
### –ó–∞–¥–∞–Ω–∏–µ 1:

```python
import re
def normalize(text: str, casefold: bool, yo2e: bool):
    text = ' '.join(text.split())
    if casefold:
        text = text.casefold()
    if yo2e:
        text = text.replace("—ë","–µ").replace('–Å', '–ï')
    return text

print(normalize("–ü—Ä–ò–≤–ï—Ç\n–ú–ò—Ä\t", True,False))
print(normalize("—ë–∂–∏–∫, –Å–ª–∫–∞", False,True))
print(normalize("Hello\r\nWorld", False,False))
print(normalize("  –¥–≤–æ–π–Ω—ã–µ   –ø—Ä–æ–±–µ–ª—ã  ", False,False))
def tokenize(text: str):
    text=text.replace(',', ' ').replace('.',' ')
    return re.sub(r'[^a-zA-Z–∞-—è–ê-–Ø0-9-\s]', '', text).split()
print(tokenize("–ø—Ä–∏–≤–µ—Ç –º–∏—Ä"))
print(tokenize("hello,world!!!"))
print(tokenize("–ø–æ-–Ω–∞—Å—Ç–æ—è—â–µ–º—É –∫—Ä—É—Ç–æ"))
print(tokenize("2025 –≥–æ–¥"))
print(tokenize("emoji üòÄ –Ω–µ —Å–ª–æ–≤–æ"))

def count_freq(tokens: list[str]):
    freq = {}
    for i in tokens:
        if i in freq:
            freq[i] += 1
        else:
            freq[i] = 1
    return freq
def top_n(freq: dict[str, int], n: int):
    s = sorted(freq.items(), key=lambda x: (-x[1], x[0]))
    return s[:n]
print(count_freq(["a","b","a","c","b","a"]))
print(top_n(count_freq(["a","b","a","c","b","a"]),2))
print((count_freq(["bb","aa","bb","aa","cc"])))
print(top_n(count_freq(["bb","aa","bb","aa","cc"]),2))
```

–†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è:

![–†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞–Ω–∏—è 1](images/lab03/text.png)

### –ó–∞–¥–∞–Ω–∏–µ 2:

```python
import sys
import io

# true - –∫—Ä–∞—Å–∏–≤—ã–π —Ç–∞–±–ª–∏—á–Ω—ã–π –≤—ã–≤–æ–¥; false - —Å—Ç–∞–Ω–¥–∞—Ä—Ç
PRETTY_TABLE_OUTPUT = True

try:
    sys.stdin = io.TextIOWrapper(sys.stdin.buffer, encoding='utf-8')
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')
except TypeError:
    pass

from text import normalize, tokenize, count_freq, top_n



def print_simple_output(total, unique, top_words):
    print(f"–í—Å–µ–≥–æ —Å–ª–æ–≤: {total}")
    print(f"–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤: {unique}")
    print("–¢–æ–ø-5:")
    for word, count in top_words:
        print(f"{word}:{count}")


def print_pretty_table(total, unique, top_words):
    print(f"–í—Å–µ–≥–æ —Å–ª–æ–≤: {total}")
    print(f"–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤: {unique}")

    if not top_words:
        print("–¢–æ–ø-5:")
        return

    header_word = "—Å–ª–æ–≤–æ"
    max_len = max([len(word) for word, count in top_words] + [len(header_word)])

    header_freq = "—á–∞—Å—Ç–æ—Ç–∞"

    print(f"{header_word:<{max_len}} | {header_freq}")
    print(f"{'-' * max_len}-+-{'-' * len(header_freq)}")

    for word, count in top_words:
        print(f"{word:<{max_len}} | {count}")


input_text = sys.stdin.read()

normalized_text = normalize(input_text, casefold=True, yo2e=True)
tokens = tokenize(normalized_text)
total_words = len(tokens)

if total_words == 0:
    print("–í—Å–µ–≥–æ —Å–ª–æ–≤: 0")
    print("–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤: 0")
    print("–¢–æ–ø-5:")
else:
    freq_dict = count_freq(tokens)
    unique_words = len(freq_dict)
    top_5_words = top_n(freq_dict, 5)

    if PRETTY_TABLE_OUTPUT:
        print_pretty_table(total_words, unique_words, top_5_words)
    else:
        print_simple_output(total_words, unique_words, top_5_words)
```
### –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –∫ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—é:

```
–ß—Ç–æ–±—ã –≤—ã–ø–æ–ª–Ω–∏—Ç—å –∫–æ–¥ —è –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª –∏–∑ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞
PRETTY_TABLE_OUTPUT - —Ä–µ–≥—É–ª–∏—Ä–æ–≤–∫–∞ –≤—ã–≤–æ–¥–∞, –ø–∞—Ä–∞–º–µ—Ç—Ä True - –∫—Ä–∞—Å–∏–≤—ã–π —Ç–∞–±–ª–∏—á–Ω—ã–π –≤—ã–≤–æ–¥
–ø–∞—Ä–∞–º–µ—Ç—Ä False - —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –≤—ã–≤–æ–¥
```

–†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è:

![–†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞–Ω–∏—è 2](images/lab03/text_stats.png)



# –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 4
### –ó–∞–¥–∞–Ω–∏–µ 1:

```python
from pathlib import Path
import csv
from typing import Iterable, Sequence


def ensure_parent_dir(path: str | Path) -> None:
    p = Path(path)
    parent = p.parent
    if parent and not parent.exists():
        parent.mkdir(parents=True, exist_ok=True)

def read_text(path: str | Path, encoding: str = "utf-8") -> str:
    p = Path(path)
    return p.read_text(encoding=encoding)


def write_csv(
        rows: Iterable[Sequence],
        path: str | Path,
        header: tuple[str, ...] | None = None
) -> None:
    rows = list(rows)

    if rows:
        length = len(rows[0])
        for r in rows:
            if len(r) != length:
                raise ValueError("–í—Å–µ —Å—Ç—Ä–æ–∫–∏ CSV –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –æ–¥–∏–Ω–∞–∫–æ–≤–æ–π –¥–ª–∏–Ω—ã")

    ensure_parent_dir(path)

    p = Path(path)
    with p.open("w", newline="", encoding="utf-8") as f:
        writer = csv.writer(f)
        if header:
            writer.writerow(header)
        for r in rows:
            writer.writerow(r)
```


### –ó–∞–¥–∞–Ω–∏–µ 2:

```python
import sys
import argparse
from pathlib import Path

from lab04.io_txt_csv import read_text, write_csv
from lib.text import normalize, tokenize, count_freq, top_n




def process_file(path: Path, encoding: str):
    text = read_text(path, encoding=encoding)
    norm = normalize(text, casefold=True, yo2e=True)
    tokens = tokenize(norm)
    return tokens


def main():
    parser = argparse.ArgumentParser(
        description="–õ–†4 ‚Äî –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á—ë—Ç–∞ –ø–æ —á–∞—Å—Ç–æ—Ç–∞–º —Å–ª–æ–≤"
    )

    parser.add_argument("--in", dest="inputs", nargs="+", default=["data/lab04/input.txt"],
                        help="–í—Ö–æ–¥–Ω—ã–µ —Ñ–∞–π–ª—ã")
    parser.add_argument("--out", dest="out", default="data/lab04/report.csv",
                        help="–í—ã—Ö–æ–¥–Ω–æ–π CSV –æ—Ç—á—ë—Ç")
    parser.add_argument("--encoding", default="utf-8", help="–ö–æ–¥–∏—Ä–æ–≤–∫–∞ –≤—Ö–æ–¥–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤")

    parser.add_argument("--per-file", dest="per_file", default=None,
                        help="CSV –æ—Ç—á—ë—Ç –ø–æ –∫–∞–∂–¥–æ–º—É —Ñ–∞–π–ª—É –æ—Ç–¥–µ–ª—å–Ω–æ (file, word, count)")
    parser.add_argument("--total", dest="total", default=None,
                        help="CSV –æ–±—â–∏–π –æ—Ç—á—ë—Ç –ø–æ –≤—Å–µ–º —Ñ–∞–π–ª–∞–º –≤–º–µ—Å—Ç–µ")

    args = parser.parse_args()

    inputs = [Path(p) for p in args.inputs]

    if len(inputs) == 1 and args.per_file is None and args.total is None:
        tokens = process_file(inputs[0], args.encoding)

        if not tokens:
            write_csv([], args.out, header=("word", "count"))
            print("–í—Å–µ–≥–æ —Å–ª–æ–≤: 0")
            print("–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤: 0")
            print("–¢–æ–ø-5:")
            return

        freq = count_freq(tokens)
        sorted_items = sorted(freq.items(), key=lambda kv: (-kv[1], kv[0]))

        write_csv(sorted_items, args.out, header=("word", "count"))

        print(f"–í—Å–µ–≥–æ —Å–ª–æ–≤: {len(tokens)}")
        print(f"–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤: {len(freq)}")

        top5 = top_n(freq, 5)
        print("–¢–æ–ø-5:")
        for w, c in top5:
            print(f"{w}:{c}")

        return

    all_tokens = []
    per_file_rows = []

    for p in inputs:
        tokens = process_file(p, args.encoding)
        all_tokens.extend(tokens)

        freq = count_freq(tokens)
        sorted_items = sorted(freq.items(), key=lambda kv: (-kv[1], kv[0]))

        for w, c in sorted_items:
            per_file_rows.append((p.name, w, c))

    if args.per_file:
        write_csv(per_file_rows, args.per_file, header=("file", "word", "count"))

    if args.total:
        freq_total = count_freq(all_tokens)
        sorted_total = sorted(freq_total.items(), key=lambda kv: (-kv[1], kv[0]))
        write_csv(sorted_total, args.total, header=("word", "count"))

if __name__ == "__main__":
    main()
```
### –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –∫ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—é:

```
–ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è —Ñ—É–Ω–∫—Ü–∏–∏ –∏–∑ –õ–†3 (normalize, tokenize, count_freq, top_n) –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞.
io_txt_csv.py —Å–æ–¥–µ—Ä–∂–∏—Ç —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è —á—Ç–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤ –∏ –∑–∞–ø–∏—Å–∏ CSV (read_text, write_csv).
text_report.py —á–∏—Ç–∞–µ—Ç –æ–¥–∏–Ω –≤—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª (input.txt), –ø–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ—Ç —á–∞—Å—Ç–æ—Ç—ã —Å–ª–æ–≤, —Å–æ—Ä—Ç–∏—Ä—É–µ—Ç –∏—Ö –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –æ—Ç—á—ë—Ç report.csv.
–ü—É—Å—Ç–æ–π —Ñ–∞–π–ª ‚Üí —Å–æ–∑–¥–∞—ë—Ç—Å—è CSV —Ç–æ–ª—å–∫–æ —Å –∑–∞–≥–æ–ª–æ–≤–∫–æ–º.
–ö–æ–¥–∏—Ä–æ–≤–∫–∞ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é UTF-8, –º–æ–∂–Ω–æ –∏–∑–º–µ–Ω–∏—Ç—å —á–µ—Ä–µ–∑ –ø–∞—Ä–∞–º–µ—Ç—Ä --encoding.
–ö–æ–Ω—Å–æ–ª—å–Ω—ã–π –≤—ã–≤–æ–¥ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–≤, —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤ –∏ —Ç–æ–ø-5 —Å–ª–æ–≤.
```

–†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è:

![–†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞–Ω–∏—è 2](images/lab04/text_report.png)
![report_csv.png](images/lab04/report_csv.png)



# –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 5
### csv_json:

```python
import json
import csv
from pathlib import Path


def csv_to_json(csv_path: str, json_path: str) -> None:
    file_csv=Path(csv_path)

    if not file_csv.exists():
        return FileNotFoundError("–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω")

    if file_csv.suffix != ".csv":
        return ValueError("–ù–µ–≤–µ—Ä–Ω—ã–π —Ç–∏–ø –¥–∞–Ω–Ω—ã—Ö")

    with open(file_csv, "r", encoding='utf-8') as f:
        reader=csv.DictReader(f)

        if reader.fieldnames is None:
            return ValueError("–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –∑–∞–≥–æ–ª–æ–≤–∫–∏ –≤ —Ñ–∞–π–ª–µ")
        dano=list(reader)
    if len(dano)==0:
        return ValueError("–ü—É—Å—Ç–æ–π —Ñ–∞–π–ª")

    with open(json_path, "w", encoding='utf-8') as f:
        json.dump(dano, f, ensure_ascii=False, indent=2)
csv_to_json("data/samples/test.csv","data/out/test_from_csv.json.json")
```
–†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è:

![–†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞–Ω–∏—è 1](images/lab05/csv_json.png)

### json_csv:

```python
import json
import csv
from pathlib import Path

def json_to_csv(json_path: str, csv_path: str) -> None:
    file_json=Path(json_path)

    if not file_json.exists():
        return FileNotFoundError("—Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω")

    try:
        with file_json.open('r',encoding='utf-8') as f:
            dano=json.load(f)
    except json.JSONDecodeError:
        return ValueError("–Ω–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞")

    except not isinstance(dano,list):
        return ValueError("JSON –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –±—ã—Ç—å –≤ –≤–∏–¥–µ —Å–ø–∏—Å–∫–∞ –æ–±—ä–µ–∫—Ç–æ–≤")

    except len(dano)==0:
        return ValueError("JSON —Ñ–∞–π–ª –ø—É—Å—Ç")

    except not all(isinstance(item, dict) for item in dano):
        return ValueError("–ö–∞–∂–¥—ã–π —ç–ª–µ–º–µ–Ω—Ç JSON –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —Å–ª–æ–≤–∞—Ä—è–º–∏")

    with open(csv_path, 'w', newline='', encoding='utf-8') as f:
            writer = csv.DictWriter(f, fieldnames=tuple(dano[0].keys()))
            writer.writeheader()
            writer.writerows(dano)
json_to_csv("data/samples/test.json","data/out/test_from_json.csv")
```

–†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è:

![–†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞–Ω–∏—è 2](images/lab05/json_csv.png)

### csv_xlsx:

```python
import csv
from pathlib import Path
from openpyxl import Workbook
from openpyxl.utils import get_column_letter

def csv_to_xlsx(csv_path: str, xlsx_path: str) -> None:
    csv_file=Path(csv_path)
    if not csv_file.exists():
        return FileNotFoundError("–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω")
    if csv_file.suffix != '.csv':
        return ValueError("–ù–µ–≤–µ—Ä–Ω—ã–π —Ç–∏–ø —Ñ–∞–π–ª–∞")
    wb=Workbook()
    ws=wb.active
    ws.title="Sheet1"

    with open(csv_path, 'r', encoding='utf-8') as f:
        reader= csv.DictReader(f)
        rows = list(reader)
    if len(rows)==0:
        return ValueError("–§–∞–π–ª –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –¥–∞–Ω–Ω—ã—Ö")
    if not reader.fieldnames:
        return ValueError("–§–∞–π–ª –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –∑–∞–≥–æ–ª–æ–≤–∫–∞")

    ws.append(reader.fieldnames)

    r_count=0
    for row in rows:
        r_count+=1

        data_for_ex=[]
        for title in reader.fieldnames:
            data_for_ex.append(row[title])
        ws.append(data_for_ex)
    if r_count == 0:
        return ValueError("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö")


    for col_index in range(1,len(reader.fieldnames)+1):
        column_letter=get_column_letter(col_index)
        max_len=0
        for row in ws[column_letter]:
            if row.value is not None:
                max_len=max(max_len,len(str(row.value)))

        m_width=max(max_len+2, 8)
        ws.column_dimensions[column_letter].width =m_width
    xlsx_path = Path(xlsx_path)
    wb.save(xlsx_path)

csv_to_xlsx("data/samples/people.csv","data/out/people.xlsx")
```

–†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è:

![–†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞–Ω–∏—è 3](images/lab05/csv_xlsx.png)


# –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 6
### cli_text:

```python
import argparse
from pathlib import Path
from src.lib.text import tokenize, count_freq, top_n

def main():
    parser = argparse.ArgumentParser(description="CLI-—É—Ç–∏–ª–∏—Ç—ã –ª–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–æ–π ‚Ññ6")
    subparsers=parser.add_subparsers(dest="command", help="–î–æ—Å—Ç—É–ø–Ω—ã–µ —Å–æ–º–∞–Ω–¥—ã")

    stats_parser = subparsers.add_parser("stats",help="–ß–∞—Å—Ç–æ—Ç—ã —Å–ª–æ–≤ –≤ —Ç–µ–∫—Å—Ç–µ")
    stats_parser.add_argument("--input", required=True, help="–í—Ö–æ–¥–Ω–æ–π —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª")
    stats_parser.add_argument("--top", type=int,default=5,help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–ø–æ–≤—ã—Ö —Å–ª–æ–≤ "
    "(–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 5)")

    cat_parser=subparsers.add_parser("cat", help="–í—ã–≤–æ–¥ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ —Ñ–∞–π–ª–∞")
    cat_parser.add_argument("--input", required=True, help="–ü—É—Ç—å –∫ –≤—Ö–æ–¥–Ω–æ–º—É —Ñ–∞–π–ª—É")
    cat_parser.add_argument("-n",action="store_true", help="–ù—É–º–µ—Ä–æ–≤–∞—Ç—å —Å—Ç—Ä–æ–∫–∏")

    args = parser.parse_args()

    file=Path(args.input)

    if not file.exists():
        raise FileNotFoundError("–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω")


    if args.command == "cat":

        with open(file, "r", encoding="utf-8") as f:
            number=1
            for row in f:
                row = row.rstrip("\n")
                if args.n:
                    print(f"{number} : {row}")
                    number+=1
                else:
                    print(row)

    elif args.command == "stats":

        with open(file, "r", encoding="utf-8") as f:
            data=[row for row in f]
        data = "".join(data)
        tokens = tokenize(text=data)
        freq = count_freq(tokens=tokens)
        top=top_n(freq=freq, n = args.top)

        number=1
        for x, y in top:
            print(f"{number}. {x} - {y}")
            number+=1
if __name__ == "__main__":
    main()
```
–†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è:

![–†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞–Ω–∏—è 1](images/lab06/cli_text1.png)
![cli_text2.png](images/lab06/cli_text2.png)
![cli_text3.png](images/lab06/cli_text3.png)

### cli_convert:

```python
import argparse
from src.lib.json_csv import json_to_csv, csv_to_json
from src.lib.csv_xlsx import csv_to_xlsx

def main():
    parser = argparse.ArgumentParser(description="–ö–æ–Ω–≤–µ—Ä—Ç–µ—Ä –¥–∞–Ω–Ω—ã—Ö –º–µ–∂–¥—É —Ñ–æ—Ä–º–∞—Ç–∞–º–∏")
    subparsers = parser.add_subparsers(dest="command", help="–î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏")

    json_to_csv_parser = subparsers.add_parser("json_to_csv", help="–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å JSON –≤ CSV")
    json_to_csv_parser.add_argument("--in", dest = "input", required= True, help="–í—Ö–æ–¥–Ω–æ–π JSON —Ñ–∞–π–ª")
    json_to_csv_parser.add_argument("--out", dest = "output", required = True, help="–í—ã—Ö–æ–¥–Ω–æ–π CSV —Ñ–∞–π–ª")


    csv_to_json_parser = subparsers.add_parser("csv_to_json", help="–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å CSV –≤ JSON")
    csv_to_json_parser.add_argument("--in", dest="input", required=True, help="–í—Ö–æ–¥–Ω–æ–π CSV —Ñ–∞–π–ª")
    csv_to_json_parser.add_argument("--out", dest="output", required=True, help="–í—ã—Ö–æ–¥–Ω–æ–π JSON —Ñ–∞–π–ª")

    csv_to_xlsx_parser = subparsers.add_parser("csv_to_xlsx", help="–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å CSV –≤ XLSX")
    csv_to_xlsx_parser.add_argument("--in", dest="input", required=True, help="–í—Ö–æ–¥–Ω–æ–π CSV —Ñ–∞–π–ª")
    csv_to_xlsx_parser.add_argument("--out", dest="output", required=True, help="–í—ã—Ö–æ–¥–Ω–æ–π XLSX —Ñ–∞–π–ª")

    args = parser.parse_args()

    if args.command == "json_to_csv":
        json_to_csv(json_path=args.input, csv_path=args.output)

    elif  args.command == "csv_to_json":
        csv_to_json(csv_path=args.input, json_path=args.output)

    elif args.command == "csv_to_xlsx":
        csv_to_xlsx(csv_path=args.input, xlsx_path=args.output)

if __name__ == "__main__":
    main()
```

–†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è:

![–†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞–Ω–∏—è 2](images/lab06/cli_convert1.png)
![cli_convert2.png](images/lab06/cli_convert2.png)
![cli_convert3.png](images/lab06/cli_convert3.png)
![cli_convert4.png](images/lab06/cli_convert4.png)


# –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 7
### test_text:

```python
import pytest

from src.lib.text import count_freq, normalize, tokenize, top_n


@pytest.mark.parametrize(
    "src,expected",
    [
        ("–ü—Ä–ò–≤–ï—Ç\n–ú–ò—Ä\t", "–ø—Ä–∏–≤–µ—Ç –º–∏—Ä"),
        ("—ë–∂–∏–∫, –Å–ª–∫–∞", "–µ–∂–∏–∫, –µ–ª–∫–∞"),
        ("Hello\r\nWorld", "hello world"),
        ("  –¥–≤–æ–π–Ω—ã–µ   –ø—Ä–æ–±–µ–ª—ã  ", "–¥–≤–æ–π–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã"),
    ],
)
def test_normalize(src, expected):
    assert normalize(src) == expected


@pytest.mark.parametrize(
    "src,expected",
    [
        ("–ø—Ä–∏–≤–µ—Ç –º–∏—Ä", ["–ø—Ä–∏–≤–µ—Ç", "–º–∏—Ä"]),
        ("hello,world!!!", ["hello", "world"]),
        ("–ø–æ-–Ω–∞—Å—Ç–æ—è—â–µ–º—É –∫—Ä—É—Ç–æ", ["–ø–æ-–Ω–∞—Å—Ç–æ—è—â–µ–º—É", "–∫—Ä—É—Ç–æ"]),
        ("2025 –≥–æ–¥", ["2025", "–≥–æ–¥"]),
        ("emoji üòÄ –Ω–µ —Å–ª–æ–≤–æ", ["emoji", "–Ω–µ", "—Å–ª–æ–≤–æ"]),
    ],
)
def test_tokenize(src, expected):
    assert tokenize(src) == expected


def test_count_and_top():
    tokens = ["a", "b", "a", "c", "b", "a"]
    freq = count_freq(tokens)
    assert freq == {"a": 3, "b": 2, "c": 1}
    assert top_n(freq, 2) == [("a", 3), ("b", 2)]


def test_top_tie_breaker():
    freq = count_freq(["bb", "aa", "bb", "aa", "cc"])
    assert top_n(freq, 2) == [("aa", 2), ("bb", 2)]


def test_dop():
    """–¢–µ—Å—Ç—ã –¥–ª—è –ø—É—Å—Ç—ã—Ö –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
    assert normalize("") == ""
    assert tokenize("") == []
    assert count_freq([]) == {}
    assert top_n({}, 5) == []


def test_top_dop():
    """–ó–∞–ø—Ä–æ—Å –±–æ–ª—å—à–µ–≥–æ N —á–µ–º –µ—Å—Ç—å —ç–ª–µ–º–µ–Ω—Ç–æ–≤"""
    freq = {"a": 3, "b": 2}
    assert top_n(freq, 5) == [("a", 3), ("b", 2)]
```
–†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è:

![–†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞–Ω–∏—è 1](images/lab07/test_text.png)

### test_json_csv:

```python
import json, csv
from pathlib import Path
import pytest
from src.lab05.json_csv import json_to_csv
from src.lab05.csv_json import csv_to_json


def write_json(path: Path, obj):
    path.write_text(json.dumps(obj, ensure_ascii=False, indent=2), encoding="utf-8")

def read_csv_rows(path: Path):
    with path.open(encoding="utf-8") as f:
        return list(csv.DictReader(f))

def test_json_to_csv_roundtrip(tmp_path: Path):
    src = tmp_path / "people.json"
    dst = tmp_path / "people.csv"
    data = [{"name": "Alice", "age": 22}, {"name": "Bob", "age": 25}]
    write_json(src, data)

    json_to_csv(str(src), str(dst))
    rows = read_csv_rows(dst)
    assert len(rows) == 2
    assert set(rows[0]) >= {"name", "age"}

def test_csv_to_json_roundtrip(tmp_path: Path):
    src = tmp_path / "people.csv"
    dst = tmp_path / "people.json"
    src.write_text("name,age\nAlice,22\nBob,25\n", encoding="utf-8")

    csv_to_json(str(src), str(dst))
    obj = json.loads(dst.read_text(encoding="utf-8"))
    assert isinstance(obj, list) and len(obj) == 2
    assert set(obj[0]) == {"name", "age"}

def test_json_to_csv_empty(tmp_path: Path):
    """–¢–µ—Å—Ç –¥–ª—è –ø—É—Å—Ç–æ–≥–æ JSON - –æ–∂–∏–¥–∞–µ–º —á—Ç–æ —Ñ—É–Ω–∫—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç–∞–µ—Ç —ç—Ç–æ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ"""
    src = tmp_path / "empty.json"
    dst = tmp_path / "empty.csv"
    src.write_text("[]", encoding="utf-8")

    try:
        json_to_csv(str(src), str(dst))
        # –ï—Å–ª–∏ —Ñ—É–Ω–∫—Ü–∏—è –≤—ã–ø–æ–ª–Ω–∏–ª–∞—Å—å –±–µ–∑ –æ—à–∏–±–∫–∏, –ø—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        if dst.exists():
            # –§–∞–π–ª —Å–æ–∑–¥–∞–Ω - —Ç–µ—Å—Ç –ø—Ä–æ–π–¥–µ–Ω
            pass
    except (ValueError, IndexError):
        pass

def test_csv_to_json_empty(tmp_path: Path):
    """–¢–µ—Å—Ç –¥–ª—è –ø—É—Å—Ç–æ–≥–æ CSV - –æ–∂–∏–¥–∞–µ–º —á—Ç–æ —Ñ—É–Ω–∫—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç–∞–µ—Ç —ç—Ç–æ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ"""
    src = tmp_path / "empty.csv"
    dst = tmp_path / "empty.json"
    src.write_text("", encoding="utf-8")

    try:
        csv_to_json(str(src), str(dst))
        # –ï—Å–ª–∏ —Ñ—É–Ω–∫—Ü–∏—è –≤—ã–ø–æ–ª–Ω–∏–ª–∞—Å—å –±–µ–∑ –æ—à–∏–±–∫–∏, –ø—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        if dst.exists():
            # –§–∞–π–ª —Å–æ–∑–¥–∞–Ω - —Ç–µ—Å—Ç –ø—Ä–æ–π–¥–µ–Ω
            pass
    except (ValueError, Exception):
        pass

def test_missing_file(tmp_path: Path):
    """–¢–µ—Å—Ç –¥–ª—è –Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ —Ñ–∞–π–ª–∞"""
    try:
        csv_to_json("nope.csv", str(tmp_path / "out.json"))
        # –ï—Å–ª–∏ —Ñ—É–Ω–∫—Ü–∏—è –≤—ã–ø–æ–ª–Ω–∏–ª–∞—Å—å, –ø—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        if (tmp_path / "out.json").exists():
            # –§–∞–π–ª —Å–æ–∑–¥–∞–Ω - —Ç–µ—Å—Ç –ø—Ä–æ–π–¥–µ–Ω
            pass
    except FileNotFoundError:
        pass
```

–†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è:

![–†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞–Ω–∏—è 2](images/lab07/test_json_csv.png)

black:

![test_json_csv_black.png](images/lab07/test_json_csv_black.png)


# –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 8
### models:

```python
from datetime import datetime, date
from dataclasses import dataclass
@dataclass
class Student:
    fio: str
    birthdate: str
    group: str
    gpa: float

    def __post_init__(self):
        #  –í–∞–ª–∏–¥–∞—Ü–∏—è birthdate
        try:
            datetime.strptime(self.birthdate, "%Y-%m-%d")
        except ValueError:
            raise ValueError(f"–ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–∞—Ç—ã: {self.birthdate}. –û–∂–∏–¥–∞–µ—Ç—Å—è YYYY-MM-DD")

        #  –í–∞–ª–∏–¥–∞—Ü–∏—è GPA
        if not (0 <= self.gpa <= 5):
            raise ValueError(f"GPA –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ 0..5, –ø–æ–ª—É—á–µ–Ω–æ: {self.gpa}")

    # –í–æ–∑—Ä–∞—Å—Ç —Å—Ç—É–¥–µ–Ω—Ç–∞
    def age(self) -> int:
        birth = datetime.strptime(self.birthdate, "%Y-%m-%d").date()
        today = date.today()
        years = today.year - birth.year
        if (today.month, today.day) < (birth.month, birth.day):
            years -= 1
        return years
    # –°–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—è
    def to_dict(self) -> dict:
        return {
            "fio": self.fio,
            "birthdate": self.birthdate,
            "group": self.group,
            "gpa": self.gpa
        }


    # –î–µ—Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—è

    @classmethod
    def from_dict(cls, d: dict):
        return cls(
            fio=d["fio"],
            birthdate=d["birthdate"],
            group=d["group"],
            gpa=d["gpa"]
        )

    def __str__(self):
        return f"{self.fio} ({self.group}), –≤–æ–∑—Ä–∞—Å—Ç: {self.age()}, GPA: {self.gpa}"


```

### serialize:

```python
import json
from .models import Student
def students_to_json(students, path):
    "–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ –≤ JSON —Ñ–∞–π–ª."
    data = [s.to_dict() for s in students]

    with open(path, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=4)

def students_from_json(path) -> list[Student]:
    "–ó–∞–≥—Ä—É–∑–∫–∞ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ –∏–∑ JSON —Ñ–∞–π–ª–∞."
    with open(path, "r", encoding="utf-8") as f:
        raw = json.load(f)

    result = []
    for d in raw:
        result.append(Student.from_dict(d))

    return result
```

–†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è:

![–†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞–Ω–∏–π](images/lab08/serialize1.png)
![serialize2.png](images/lab08/serialize2.png)
